---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
Research Interest
======
**Visual Correspondence** and its applications. e.g., Semantic Correspondence, Few-shot Segmentation, 3D Reconstruction, Novel View Synthesis, etc. Specifically, I am interested in effective model architecture for transformers or designing efficient methods for correspondence. <br>
**Generative Models**. e.g., Diffusion Models, Image-to-Image Translation, etc. <br>
**Multimodal Learning**. e.g., Zero-shot Segmentation, Text-guided Image Manipulation, etc. <br>

Education
======

* Korea University, Seoul, Korea
  * M.S./Ph.D. Integrated Student in Computer Science and Engineering
  * Mar. 2022 - Present

* Yonsei University, Seoul, Korea
  * B.S. in Computer Science
  * Mar. 2018 - Feb. 2022

Experience
======
* Adobe, San Jose, CA
  * Research Intern
  * June. 2023 - Sep. 2023
  * Mentor: <a href="https://joonyoung-cv.github.io">Joon-Young Lee</a>, <a href="https://gabriel-huang.github.io">Gabriel Huang</a>

Publications
======

## International Journal

> <i style='font-style: normal;'>**CATs++: Boosting Cost Aggregation with Convolutions and Transformers**<br></i>
>> <i style='font-style: normal;'>**Seokju Cho**\*, Sunghwan Hong*, and Seungryong Kim<br></i>
>> <i style='font-style: normal;'>IEEE Trans. on Pattern Analysis and Machine Intelligence (**TPAMI**), <br> To be appeared (Impact Factor: 24.314).<br></i>
>> <i style='font-style: normal;'><a href="https://ku-cvlab.github.io/CATs-PlusPlus-Project-Page/">[Project Page]</a> <a href="https://arxiv.org/abs/2202.06817">[arXiv]</a>

## International Conference

> <i style='font-style: normal;'>**Unifying Feature and Cost Aggregation with Transformers for Dense Correspondence**<br></i>
>> <i style='font-style: normal;'>Sunghwan Hong*, **Seokju Cho**\*, Seungryong Kim, and Stephen Lin<br></i>
>> <i style='font-style: normal;'>International Conference on Learning Representations (**ICLR**), 2024.<br></i>
<!-- >> <i style='font-style: normal;'><a href="https://ku-cvlab.github.io/DaRF/">[Project Page]</a> <a href="https://arxiv.org/abs/2305.19201">[arXiv]</a>  -->

> <i style='font-style: normal;'>**D√§RF: Boosting Radiance Fields from Sparse Inputs with Monocular Depth Adaptation**<br></i>
>> <i style='font-style: normal;'>Jiuhn Song\*, Seonghoon Park\*, Honggyu An\*, **Seokju Cho**, Min-Seop Kwak, Sungjin Cho, and Seungryong Kim<br></i>
>> <i style='font-style: normal;'>Neural Information Processing Systems (**NeurIPS**), 2023.<br></i>
>> <i style='font-style: normal;'><a href="https://ku-cvlab.github.io/DaRF/">[Project Page]</a> <a href="https://arxiv.org/abs/2305.19201">[arXiv]</a> 

> <i style='font-style: normal;'>**LANIT: Language-Driven Image-to-Image Translation for Unlabeled Data**<br></i>
>> <i style='font-style: normal;'>Jihye Park\*, Sunwoo Kim\*, Soohyun Kim\*, **Seokju Cho**, Jaejun Yoo, Youngjung Uh, and Seungryong Kim<br></i>
>> <i style='font-style: normal;'>IEEE Conference Computer Vision Pattern Recognition (**CVPR**), 2023.<br></i>
>> <i style='font-style: normal;'><a href="https://ku-cvlab.github.io/LANIT/">[Project Page]</a> <a href="https://arxiv.org/abs/2208.14889">[arXiv]</a> 

> <i style='font-style: normal;'>**MIDMs: Matching Interleaved Diffusion Models for Exemplar-based Image Translation**<br></i>
>> <i style='font-style: normal;'>Junyoung Seo\*, Gyuseong Lee\*, **Seokju Cho**, Jiyoung Lee, Seungryong Kim<br></i>
>> <i style='font-style: normal;'>AAAI Conference on Artificial Intelligence (**AAAI**), 2023.<br></i>
>> <i style='font-style: normal;'><a href="https://ku-cvlab.github.io/MIDMs/">[Project Page]</a> <a href="https://arxiv.org/abs/2209.11047">[arXiv]</a> 

> <i style='font-style: normal;'>**Neural Matching Fields: Implicit Representation of Matching Fields for Visual Correspondence**<br></i>
>> <i style='font-style: normal;'>Sunghwan Hong, Jisu Nam, **Seokju Cho**, Susung Hong,  Sangryul Jeon, Dongbo Min, and Seungryong Kim<br></i>
>> <i style='font-style: normal;'>Neural Information Processing Systems (**NeurIPS**), 2022.<br></i>
>> <i style='font-style: normal;'><a href="https://ku-cvlab.github.io/NeMF/">[Project Page]</a> <a href="https://arxiv.org/abs/2210.02689">[arXiv]</a> 

> <i style='font-style: normal;'>**Cost Aggregation with 4D Convolutional Swin Transformer for Few-Shot Segmentation**<br></i>
>> <i style='font-style: normal;'>Sunghwan Hong*, **Seokju Cho**\*, Jisu Nam, Stephen Lin, and Seungryong Kim<br></i>
>> <i style='font-style: normal;'>European Conference on Computer Vision (**ECCV**), 2022.<br></i>
>> <i style='font-style: normal;'><a href="https://seokju-cho.github.io/VAT/">[Project Page]</a> <a href="https://arxiv.org/abs/2207.10866">[arXiv]</a> 
<!-- <a href="https://github.com/Seokju-Cho/Volumetric-Aggregation-Transformer">[Github]</a> -->

> <i style='font-style: normal;'>**CATs: Cost Aggregation Transformers for Visual Correspondence**</i>
>> <i style='font-style: normal;'>**Seokju Cho**\*, Sunghwan Hong*, Sangryul Jeon, Yunsung Lee, Kwanghoon Sohn, and Seungryong Kim<br></i>
>> <i style='font-style: normal;'>Neural Information Processing Systems (**NeurIPS**), 2021.<br></i>
>> <i style='font-style: normal;'><a href="https://sunghwanhong.github.io/CATs/">[Project Page]</a> <a href="https://arxiv.org/abs/2106.02520">[arXiv]</a> <a href="https://github.com/SunghwanHong/Cost-Aggregation-transformers">[Github]</a>
</i>


## Preprints

> <i style='font-style: normal;'>**CAT-Següê±: Cost Aggregation for Open-Vocabulary Semantic Segmentation**<br></i>
>> <i style='font-style: normal;'>**Seokju Cho**\*, Heeseong Shin\*, Sunghwan Hong, Seungjun An, Seungjun Lee, Anurag Arnab, Paul Hongsuck Seo, and Seungryong Kim<br></i>
>> <i style='font-style: normal;'>ArXiv Preprint, 2023.<br></i>
>> <i style='font-style: normal;'><a href="https://ku-cvlab.github.io/CAT-Seg/">[Project Page]</a> <a href="https://arxiv.org/abs/2303.11797">[arXiv]</a> 

> <i style='font-style: normal;'>**DiffFace: Diffusion-based Face Swapping with Facial Guidance**<br></i>
>> <i style='font-style: normal;'>Kihong Kim\*, Yunho Kim\*, **Seokju Cho**, Junyoung Seo, Jisu Nam, Kychul Lee, Seungryong Kim, KwangHee Lee<br></i>
>> <i style='font-style: normal;'>ArXiv Preprint, 2022.<br></i>
>> <i style='font-style: normal;'><a href="https://hxngiee.github.io/DiffFace/">[Project Page]</a> <a href="https://arxiv.org/abs/2212.13344">[arXiv]</a> 

> <i style='font-style: normal;'>**Integrative Feature and Cost Aggregation with Transformers for Dense Correspondence**<br></i>
>> <i style='font-style: normal;'>Sunghwan Hong\*, **Seokju Cho**\*, Seungryong Kim, Stephen Lin<br></i>
>> <i style='font-style: normal;'>ArXiv Preprint, 2022.<br></i>
>> <i style='font-style: normal;'><a href="https://arxiv.org/abs/2209.08742">[arXiv]</a> 

> <i style='font-style: normal;'>**AggMatch: Aggregating Pseudo Labels for Semi-Supervised Learning**<br></i>
>> <i style='font-style: normal;'>Jiwon Kim\*, Kwangrok Ryoo\*, Gyuseong Lee, **Seokju Cho**, Junyoung Seo, Daehwan Kim, Hansang Cho, and Seungryong Kim (Under Review)<br></i>
>> <i style='font-style: normal;'>ArXiv Preprint, 2021.<br></i>
>> <i style='font-style: normal;'><a href="https://arxiv.org/abs/2201.10444">[arXiv]</a>

Academic Services
======
### Reviewer
* 2023 - **CVPR**, **NeurIPS**

Honors
======
* Ministry of Science and ICT & National IT Industry Promotion Agency, Sep. 2021
  * AI Online Competition, 3rd Place Award, Won 300M KRW

Skills
======
* Deep Learning, Machine Learning
  * Pytorch, Numpy
* Programming Languages
  * Python, JavaScript, C/C++
* Web Framework
  * React, Node.js, Flask
